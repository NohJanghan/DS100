{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 10 â€“ Data 100, Summer 2025\n",
    "\n",
    "Data 100, Summer 2025\n",
    "\n",
    "[Acknowledgments Page](https://ds100.org/su25/acks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "Recreate the 4 correlation plots in slides. (This wouldn't normally be in the notebook, but it might be of interest to you.)\n",
    "\n",
    "Note: We use `np.corrcoef` to compute the correlation coefficient $r$, though we could also compute it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed recreate same random points as slides\n",
    "np.random.seed(43)\n",
    "plt.style.use('default') # Revert style to default mpl\n",
    "\n",
    "def plot_and_get_corr(ax, x, y, title):\n",
    "    ax.set_xlim(-3, 3)\n",
    "    ax.set_ylim(-3, 3)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.scatter(x, y, alpha = 0.73)\n",
    "    ax.set_title(title)\n",
    "    return np.corrcoef(x, y)[0, 1]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize = (10, 10))\n",
    "\n",
    "# Just noise\n",
    "x1, y1 = np.random.randn(2, 100)\n",
    "corr1 = plot_and_get_corr(axs[0, 0], x1, y1, title = \"noise\")\n",
    "\n",
    "# Strong linear\n",
    "x2 = np.linspace(-3, 3, 100)\n",
    "y2 = x2 * 0.5 - 1 + np.random.randn(100) * 0.3\n",
    "corr2 = plot_and_get_corr(axs[0, 1], x2, y2, title = \"strong linear\")\n",
    "\n",
    "# Unequal spread\n",
    "x3 = np.linspace(-3, 3, 100)\n",
    "y3 = - x3/3 + np.random.randn(100)*(x3)/2.5\n",
    "corr3 = plot_and_get_corr(axs[1, 0], x3, y3, title = \"strong linear\")\n",
    "extent = axs[1, 0].get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "\n",
    "# Strong non-linear\n",
    "x4 = np.linspace(-3, 3, 100)\n",
    "y4 = 2*np.sin(x3 - 1.5) + np.random.randn(100) * 0.3\n",
    "corr4 = plot_and_get_corr(axs[1, 1], x4, y4, title = \"strong non-linear\")\n",
    "\n",
    "plt.show()\n",
    "print([corr1, corr2, corr3, corr4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which $\\theta$ is best?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "lw = pd.read_csv(\"data/little_women.csv\")\n",
    "fig = plt.figure(figsize = (5, 5))\n",
    "ax = plt.gca()\n",
    "sns.scatterplot(data=lw, x=\"Periods\", y=\"Characters\", ax=ax)\n",
    "\n",
    "xlims = np.array([50, 450])\n",
    "params = [[5000, 100], [50000, -50], [-4000, 150]]\n",
    "for i, (theta_0, theta_1) in enumerate(params):\n",
    "    ax.plot(xlims, theta_0 + theta_1 * xlims, lw=2, label=f\"{i+1}. ($\\\\theta_0$: {theta_0}, $\\\\theta_1$: {theta_1})\")\n",
    "ax.legend()\n",
    "\n",
    "# The best parameters weren't one of the choices\n",
    "ahat_true, bhat_true = 4745, 87\n",
    "fig.tight_layout()\n",
    "# plt.savefig('lw_params.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's implement the tools we'll need for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_units(x):\n",
    "    return (x - np.mean(x)) / np.std(x)\n",
    "\n",
    "def correlation(x, y):\n",
    "    return np.mean(standard_units(x) * standard_units(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(x, y):\n",
    "    return correlation(x, y) * np.std(y) / np.std(x)\n",
    "\n",
    "def intercept(x, y):\n",
    "    return np.mean(y) - slope(x, y) * np.mean(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def fit_least_squares(x, y):\n",
    "    theta_0 = intercept(x, y)\n",
    "    theta_1 = slope(x, y)\n",
    "    return theta_0, theta_1\n",
    "\n",
    "def predict(x, theta_0, theta_1):\n",
    "    return theta_0 + theta_1 * x\n",
    "\n",
    "def compute_mse(y, yhat):\n",
    "    return np.mean((y - yhat) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we define `least_squares_evaluation`, which:\n",
    "* Computes general data statistics like mean, standard deviation, and linear correlation $r$\n",
    "* Fits least squares to data of the form $(x, y)$\n",
    "* Computes performance metrics like RMSE\n",
    "* Plots two visualizations:\n",
    "    * Original scatter plot with a fitted line\n",
    "    * Residual plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default') # Revert style to default mpl\n",
    "NO_VIZ, RESID, RESID_SCATTER = range(3)\n",
    "def least_squares_evaluation(x, y, visualize = NO_VIZ):\n",
    "    theta_0, theta_1 = fit_least_squares(x, y)\n",
    "    yhat = predict(x, theta_0, theta_1)\n",
    "    \n",
    "    # Statistics Performance metrics\n",
    "    if visualize == NO_VIZ:\n",
    "        print(f\"x_mean : {np.mean(x):.2f}, y_mean : {np.mean(y):.2f}\")\n",
    "        print(f\"x_stdev: {np.std(x):.2f}, y_stdev: {np.std(y):.2f}\")\n",
    "        print(f\"r = Correlation(x, y): {correlation(x, y):.3f}\")\n",
    "        print(f\"theta_0: {theta_0:.2f}, theta_1: {theta_1:.2f}\")\n",
    "        print(f\"RMSE: {np.sqrt(compute_mse(y, yhat)):.3f}\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axs = None, None\n",
    "    if visualize == RESID:\n",
    "        fig = plt.figure(figsize = (4, 3))\n",
    "        plt.scatter(x, y - yhat, color = 'red')\n",
    "        plt.axhline(y = 0, xmin = 0, xmax = 500)\n",
    "        fig.axes[0].set_title(\"Residuals\")\n",
    "        \n",
    "        \n",
    "    if visualize == RESID_SCATTER:\n",
    "        fig, axs = plt.subplots(1, 2, figsize = (8, 3))\n",
    "        axs[0].scatter(x, y)\n",
    "        axs[0].plot(x, yhat)\n",
    "        axs[0].set_title(\"LS fit\")\n",
    "        axs[1].scatter(x, y - yhat, color = 'red')\n",
    "        axs[1].axhline(y = 0, xmin = 0, xmax = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first try just doing linear fit *without* visualizing data.\n",
    "\n",
    "**Note**: Computation without visualization is NOT a good practice! We are doing the three evaluation steps **out of order** to highlight the importance of visualization.\n",
    "\n",
    "Here are the evaluation steps **in order**:\n",
    "1. Visualize original data and compute statistics.\n",
    "2. If it seems reasonable, fit the linear model.\n",
    "3. Finally, compute performance metrics of linear model and plot residuals and other visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute statistics and performance metrics only (Anscombe's Quartet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5]\n",
    "y1 = [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68]\n",
    "y2 = [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74]\n",
    "y3 = [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73]\n",
    "x4 = [8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8]\n",
    "y4 = [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89]\n",
    "\n",
    "anscombe = {\n",
    "    'I': pd.DataFrame(list(zip(x, y1)), columns =['x', 'y']),\n",
    "    'II': pd.DataFrame(list(zip(x, y2)), columns =['x', 'y']),\n",
    "    'III': pd.DataFrame(list(zip(x, y3)), columns =['x', 'y']),\n",
    "    'IV': pd.DataFrame(list(zip(x4, y4)), columns =['x', 'y'])\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize = (10, 10))\n",
    "\n",
    "for i, dataset in enumerate(['I', 'II', 'III', 'IV']):\n",
    "    ans = anscombe[dataset]\n",
    "    axs[i//2, i%2].scatter(ans['x'], ans['y'])\n",
    "    axs[i//2, i%2].set_title(f\"Dataset {dataset}\")\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in ['I', 'II', 'III', 'IV']:\n",
    "    print(f\">>> Dataset {dataset}:\")\n",
    "    ans = anscombe[dataset]\n",
    "    least_squares_evaluation(ans['x'], ans['y'], visualize = NO_VIZ)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, looks like all four datasets have the same:\n",
    "* Statistics of $x$ and $y$\n",
    "* Correlation $r$\n",
    "* Regression line parameters $\\hat{a}, \\hat{b}$\n",
    "* RMSE (average squared loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in ['I', 'II', 'III', 'IV']:\n",
    "    print(f\">>> Dataset {dataset}:\")\n",
    "    ans = anscombe[dataset]\n",
    "    fig = least_squares_evaluation(ans['x'], ans['y'], visualize = RESID)\n",
    "    plt.show(fig)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the original data (what we should have done at the beginning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in ['I', 'II', 'III', 'IV']:\n",
    "    print(f\">>> Dataset {dataset}:\")\n",
    "    ans = anscombe[dataset]\n",
    "    fig = least_squares_evaluation(ans['x'], ans['y'], visualize = RESID_SCATTER)\n",
    "    plt.show(fig)\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
